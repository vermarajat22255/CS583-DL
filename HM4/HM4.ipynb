{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "HM4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2B5Pas187VPQ"
      },
      "source": [
        "# Home 3: Build a CNN for image recognition.\n",
        "\n",
        "### Name: [Rajat Verma]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82UKLYqi7VPT"
      },
      "source": [
        "## 0. You will do the following:\n",
        "\n",
        "1. Read, complete, and run the code.\n",
        "\n",
        "2. **Make substantial improvements** to maximize the accurcy.\n",
        "    \n",
        "3. Convert the .IPYNB file to .HTML file.\n",
        "\n",
        "    * The HTML file must contain the code and the output after execution.\n",
        "    \n",
        "    \n",
        "4. Upload this .HTML file to your Google Drive, Dropbox, or Github repo.\n",
        "\n",
        "4. Submit the link to this .HTML file to Canvas.\n",
        "\n",
        "    * Example: https://github.com/wangshusen/CS583-2019F/blob/master/homework/HM3/HM3.html\n",
        "\n",
        "\n",
        "## Requirements:\n",
        "\n",
        "1. You can use whatever CNN architecture, including VGG, Inception, and ResNet. However, you must build the networks layer by layer. You must NOT import the archetectures from ```keras.applications```.\n",
        "\n",
        "2. Make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer.\n",
        "\n",
        "3. If you want to regularize a ```Conv```/```Dense``` layer, you should place a ```Dropout``` layer **before** the ```Conv```/```Dense``` layer.\n",
        "\n",
        "4. An accuracy above 70% is considered reasonable. An accuracy above 80% is considered good. Without data augmentation, achieving 80% accuracy is difficult.\n",
        "\n",
        "\n",
        "## Google Colab\n",
        "\n",
        "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option.\n",
        "\n",
        "- Keep in mind that you must download it as an IPYNB file and then use IPython Notebook to convert it to HTML.\n",
        "\n",
        "- Also keep in mind that the IPYNB and HTML files must contain the outputs. (Otherwise, the instructor will not be able to know the correctness and performance.) Do the followings to keep the outputs.\n",
        "\n",
        "- In Colab, go to ```Runtime``` --> ```Change runtime type``` --> Do NOT check ```Omit code cell output when saving this notebook```. In this way, the downloaded IPYNB file contains the outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Di6GiGnV7VPW"
      },
      "source": [
        "## 1. Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTNDM1xm7VPX"
      },
      "source": [
        "### 1.1. Load data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w6YBUhv7VPY",
        "outputId": "dbcb6238-745e-444a-9443-af56146e5f52"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "import numpy\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print('shape of x_train: ' + str(x_train.shape))\n",
        "print('shape of y_train: ' + str(y_train.shape))\n",
        "print('shape of x_test: ' + str(x_test.shape))\n",
        "print('shape of y_test: ' + str(y_test.shape))\n",
        "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of x_train: (50000, 32, 32, 3)\n",
            "shape of y_train: (50000, 1)\n",
            "shape of x_test: (10000, 32, 32, 3)\n",
            "shape of y_test: (10000, 1)\n",
            "number of classes: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8NhPztA7VPZ"
      },
      "source": [
        "### 1.2. One-hot encode the labels\n",
        "\n",
        "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
        "\n",
        "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
        "\n",
        "2. Apply the function to ```y_train``` and ```y_test```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSiU5hDz7VPa",
        "outputId": "5c86f66d-84f0-4e94-ca97-122808c40c45"
      },
      "source": [
        "def to_one_hot(y, num_class=10):\n",
        "    result = numpy.zeros((len(y),num_class))\n",
        "    for i,y in enumerate(y):\n",
        "        result[i,y]=1\n",
        "    return result\n",
        "\n",
        "y_train_vec = to_one_hot(y_train)\n",
        "y_test_vec = to_one_hot(y_test)\n",
        "\n",
        "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
        "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
        "\n",
        "print(y_train[0])\n",
        "print(y_train_vec[0])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of y_train_vec: (50000, 10)\n",
            "Shape of y_test_vec: (10000, 10)\n",
            "[6]\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3_EG0DR7VPb"
      },
      "source": [
        "#### Remark: the outputs should be\n",
        "* Shape of y_train_vec: (50000, 10)\n",
        "* Shape of y_test_vec: (10000, 10)\n",
        "* [6]\n",
        "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gHldK467VPc"
      },
      "source": [
        "### 1.3. Randomly partition the training set to training and validation sets\n",
        "\n",
        "Randomly partition the 50K training samples to 2 sets:\n",
        "* a training set containing 40K samples\n",
        "* a validation set containing 10K samples\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKzeAq3V7VPc",
        "outputId": "71c057bd-e803-4d9d-c779-d986558d8cd7"
      },
      "source": [
        "rand_indices = numpy.random.permutation(50000)\n",
        "train_indices = rand_indices[0:40000]\n",
        "valid_indices = rand_indices[40000:50000]\n",
        "\n",
        "x_val = x_train[valid_indices, :]\n",
        "y_val = y_train_vec[valid_indices, :]\n",
        "\n",
        "x_tr = x_train[train_indices, :]\n",
        "y_tr = y_train_vec[train_indices, :]\n",
        "\n",
        "print('Shape of x_tr: ' + str(x_tr.shape))\n",
        "print('Shape of y_tr: ' + str(y_tr.shape))\n",
        "print('Shape of x_val: ' + str(x_val.shape))\n",
        "print('Shape of y_val: ' + str(y_val.shape))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_tr: (40000, 32, 32, 3)\n",
            "Shape of y_tr: (40000, 10)\n",
            "Shape of x_val: (10000, 32, 32, 3)\n",
            "Shape of y_val: (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUiCD_IF7VPd"
      },
      "source": [
        "## 2. Build a CNN and tune its hyper-parameters\n",
        "\n",
        "1. Build a convolutional neural network model\n",
        "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
        "    * Do NOT use test data for hyper-parameter tuning!!!\n",
        "3. Try to achieve a validation accuracy as high as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6lROQzY7VPe"
      },
      "source": [
        "### Remark: \n",
        "\n",
        "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
        "* Add more layers.\n",
        "* Use regularizations, e.g., dropout.\n",
        "* Use batch normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lWJlEP37VPf",
        "outputId": "93cee227-06c4-4f0c-8aaf-9c19d042b4e4"
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dropout(0.2)) \n",
        "model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Dropout(0.2))  \n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Dropout(0.2)) \n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 664,682\n",
            "Trainable params: 663,658\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poAA7atJ7VPf"
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "learning_rate = 1E-3 # to be tuned!\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQBQH89O9adj"
      },
      "source": [
        "#Code to implement data augmentation\n",
        "# from keras.preprocessing.image import ImageDataGenerator\n",
        "# datagen = ImageDataGenerator(rotation_range=40, width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True)\n",
        "# it_train = datagen.flow(x_tr, y_tr, batch_size=128)\n",
        "# history = model.fit_generator(it_train, steps_per_epoch = int(x_tr.shape[0] / 128), epochs=40, validation_data=(x_val, y_val))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JscpoTDy7VPg",
        "outputId": "a7d54b6d-c5a9-4253-baa3-a0b6f7213463"
      },
      "source": [
        "history = model.fit(x_tr, y_tr, batch_size=64, epochs=30, validation_data=(x_val, y_val))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "625/625 [==============================] - 10s 10ms/step - loss: 2.0580 - acc: 0.3349 - val_loss: 1.8252 - val_acc: 0.4050\n",
            "Epoch 2/30\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 1.2138 - acc: 0.5615 - val_loss: 1.4288 - val_acc: 0.5300\n",
            "Epoch 3/30\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 1.0051 - acc: 0.6418 - val_loss: 1.1226 - val_acc: 0.6036\n",
            "Epoch 4/30\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.8987 - acc: 0.6870 - val_loss: 0.8763 - val_acc: 0.6969\n",
            "Epoch 5/30\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.8374 - acc: 0.7069 - val_loss: 0.7752 - val_acc: 0.7252\n",
            "Epoch 6/30\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.7836 - acc: 0.7226 - val_loss: 0.7876 - val_acc: 0.7217\n",
            "Epoch 7/30\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.7341 - acc: 0.7483 - val_loss: 0.8117 - val_acc: 0.7222\n",
            "Epoch 8/30\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.7053 - acc: 0.7508 - val_loss: 0.7314 - val_acc: 0.7528\n",
            "Epoch 9/30\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.6726 - acc: 0.7655 - val_loss: 0.6795 - val_acc: 0.7667\n",
            "Epoch 10/30\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.6433 - acc: 0.7767 - val_loss: 1.0102 - val_acc: 0.6904\n",
            "Epoch 11/30\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.6221 - acc: 0.7846 - val_loss: 0.6835 - val_acc: 0.7624\n",
            "Epoch 12/30\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.6024 - acc: 0.7905 - val_loss: 0.7257 - val_acc: 0.7548\n",
            "Epoch 13/30\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.5810 - acc: 0.7967 - val_loss: 0.5949 - val_acc: 0.7987\n",
            "Epoch 14/30\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.5698 - acc: 0.8026 - val_loss: 0.5734 - val_acc: 0.8078\n",
            "Epoch 15/30\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.5468 - acc: 0.8102 - val_loss: 0.5816 - val_acc: 0.8031\n",
            "Epoch 16/30\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.5396 - acc: 0.8129 - val_loss: 0.5882 - val_acc: 0.7999\n",
            "Epoch 17/30\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.5214 - acc: 0.8227 - val_loss: 0.6162 - val_acc: 0.7950\n",
            "Epoch 18/30\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.5208 - acc: 0.8214 - val_loss: 0.5579 - val_acc: 0.8133\n",
            "Epoch 19/30\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.4967 - acc: 0.8296 - val_loss: 0.6442 - val_acc: 0.7852\n",
            "Epoch 20/30\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.4986 - acc: 0.8272 - val_loss: 0.6003 - val_acc: 0.7966\n",
            "Epoch 21/30\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.4937 - acc: 0.8288 - val_loss: 0.6033 - val_acc: 0.7978\n",
            "Epoch 22/30\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.4918 - acc: 0.8322 - val_loss: 0.5945 - val_acc: 0.7983\n",
            "Epoch 23/30\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.4768 - acc: 0.8334 - val_loss: 0.6048 - val_acc: 0.7990\n",
            "Epoch 24/30\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.4649 - acc: 0.8411 - val_loss: 0.5877 - val_acc: 0.8046\n",
            "Epoch 25/30\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.4794 - acc: 0.8380 - val_loss: 0.7002 - val_acc: 0.7739\n",
            "Epoch 26/30\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.4619 - acc: 0.8452 - val_loss: 0.6187 - val_acc: 0.8073\n",
            "Epoch 27/30\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.4660 - acc: 0.8428 - val_loss: 0.5385 - val_acc: 0.8244\n",
            "Epoch 28/30\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.4458 - acc: 0.8483 - val_loss: 0.5425 - val_acc: 0.8213\n",
            "Epoch 29/30\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.4515 - acc: 0.8501 - val_loss: 0.5495 - val_acc: 0.8184\n",
            "Epoch 30/30\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.4572 - acc: 0.8466 - val_loss: 0.6003 - val_acc: 0.8067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "pDloXvv27VPg",
        "outputId": "3205423f-6f92-46b1-b5c2-fecd4a890c52"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIzdN4yX7VPh"
      },
      "source": [
        "## 3. Train (again) and evaluate the model\n",
        "\n",
        "- To this end, you have found the \"best\" hyper-parameters. \n",
        "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
        "- Evaluate your model on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QY_vjRta7VPi"
      },
      "source": [
        "### 3.1. Train the model on the entire training set\n",
        "\n",
        "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD9nSIWF7VPj"
      },
      "source": [
        "# <Compile your model again (using the same hyper-parameters)>\n",
        "learning_rate = 1E-3 # to be tuned!\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wd4oWTxk7VPk",
        "outputId": "3f526f43-5bf4-446f-c803-31ff4fcc0538"
      },
      "source": [
        "# <Train your model on the entire training set (50K samples)>\n",
        "# <Use (x_train, y_train_vec) instead of (x_tr, y_tr)>\n",
        "# <Do NOT use the validation_data option (because now you do not have validation data)>\n",
        "history = model.fit(x_train, y_train_vec, batch_size=64, epochs=30)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "782/782 [==============================] - 8s 9ms/step - loss: 0.5254 - acc: 0.8252\n",
            "Epoch 2/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.5072 - acc: 0.8338\n",
            "Epoch 3/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4993 - acc: 0.8353\n",
            "Epoch 4/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.5020 - acc: 0.8322\n",
            "Epoch 5/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.5009 - acc: 0.8340\n",
            "Epoch 6/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4921 - acc: 0.8361\n",
            "Epoch 7/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4865 - acc: 0.8388\n",
            "Epoch 8/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4905 - acc: 0.8353\n",
            "Epoch 9/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4979 - acc: 0.8389\n",
            "Epoch 10/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4839 - acc: 0.8402\n",
            "Epoch 11/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4813 - acc: 0.8399\n",
            "Epoch 12/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4861 - acc: 0.8434\n",
            "Epoch 13/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4782 - acc: 0.8417\n",
            "Epoch 14/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4910 - acc: 0.8383\n",
            "Epoch 15/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4845 - acc: 0.8423\n",
            "Epoch 16/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4886 - acc: 0.8412\n",
            "Epoch 17/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4831 - acc: 0.8409\n",
            "Epoch 18/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4816 - acc: 0.8430\n",
            "Epoch 19/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4855 - acc: 0.8426\n",
            "Epoch 20/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4820 - acc: 0.8408\n",
            "Epoch 21/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4795 - acc: 0.8435\n",
            "Epoch 22/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4777 - acc: 0.8422\n",
            "Epoch 23/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4771 - acc: 0.8420\n",
            "Epoch 24/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4796 - acc: 0.8446\n",
            "Epoch 25/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4689 - acc: 0.8481\n",
            "Epoch 26/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4663 - acc: 0.8454\n",
            "Epoch 27/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4702 - acc: 0.8427\n",
            "Epoch 28/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4777 - acc: 0.8440\n",
            "Epoch 29/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4732 - acc: 0.8436\n",
            "Epoch 30/30\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4704 - acc: 0.8457\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXvkVML47VPk"
      },
      "source": [
        "### 3.2. Evaluate the model on the test set\n",
        "\n",
        "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Rg0QdnO7VPl",
        "outputId": "504f7cad-8fdc-43d3-8910-422995587608"
      },
      "source": [
        "loss_and_acc = model.evaluate(x_test, y_test_vec)\n",
        "print('loss = ' + str(loss_and_acc[0]))\n",
        "print('accuracy = ' + str(loss_and_acc[1]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.5741 - acc: 0.8196\n",
            "loss = 0.5740983486175537\n",
            "accuracy = 0.819599986076355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i8gEcXy7VPm"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}